{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Input-as-Output performance by input class-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from comparative_viz import ComparativeViz\n",
    "from equality_experiment import InputAsOutputExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = InputAsOutputExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(ex):\n",
    "    left, right = ex\n",
    "    half = int(left.shape[0] / 2)\n",
    "\n",
    "    a = left[: half]\n",
    "    b = left[half: ]\n",
    "\n",
    "    left_label = np.array_equal(a, b)\n",
    "    left_label = \"same\" if left_label else \"different\"\n",
    "\n",
    "    c = right[: half]\n",
    "    d = right[half: ]\n",
    "\n",
    "    right_label = np.array_equal(c, d)\n",
    "    right_label = \"same\" if right_label else \"different\"\n",
    "\n",
    "    x_label = \"{}/{}\".format(left_label, right_label)\n",
    "\n",
    "    return x_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_class_accuracy(ex_classes, preds, y_test):\n",
    "    cm = defaultdict(list)\n",
    "    for cls, gold, pred in zip(ex_classes, preds, y_test):\n",
    "        cm[cls].append(int(gold == pred))\n",
    "    acc = {}\n",
    "    for cls, scores in cm.items():\n",
    "        acc[cls] = sum(scores) / len(scores)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(n_trials=20, embed_dim=25, lr=0.01, alpha=0.0001, train_sizes=list(range(104, 2001, 100))):\n",
    "    data = []\n",
    "    for trial in range(1, n_trials+1):\n",
    "\n",
    "        # Model with the best parameters we found experimentally:\n",
    "        mod = experiment.get_model(\n",
    "            hidden_dim=embed_dim * 2,\n",
    "            alpha=alpha,\n",
    "            lr=lr,\n",
    "            embed_dim=embed_dim)\n",
    "\n",
    "        # Dataset:\n",
    "        X_train, X_test, y_train, y_test, test_dataset = \\\n",
    "            experiment.get_new_train_and_test_sets(embed_dim)\n",
    "        ex_classes = [classify_example(ex) for ex in X_test]\n",
    "\n",
    "        # Zero-shot predictions\n",
    "        preds = mod.predict(X_test)\n",
    "        accs = get_per_class_accuracy(ex_classes, preds, y_test)\n",
    "\n",
    "        for cls, acc in accs.items():\n",
    "            d = {\n",
    "                'trial': trial,\n",
    "                'train_size': 0,\n",
    "                'embed_dim': embed_dim,\n",
    "                'hidden_dim': embed_dim * 2,\n",
    "                'alpha': alpha,\n",
    "                'learning_rate': lr,\n",
    "                'input_class': cls,\n",
    "                'accuracy': acc,\n",
    "                'batch_pos': 0,\n",
    "                'batch_neg': 0}\n",
    "            d.update(accs)\n",
    "            data.append(d)\n",
    "\n",
    "        # With additional training:\n",
    "        for train_size in train_sizes:\n",
    "\n",
    "            X_batch = X_train[ : train_size]\n",
    "            y_batch = y_train[ : train_size]\n",
    "            batch_pos = sum([1 for label in y_train[ : train_size] if label == 1])\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                mod.fit(X_batch, y_batch)\n",
    "\n",
    "                preds = mod.predict(X_test)\n",
    "                accs = get_per_class_accuracy(ex_classes, preds, y_test)\n",
    "\n",
    "                for cls, acc in accs.items():\n",
    "                    d = {\n",
    "                        'trial': trial,\n",
    "                        'train_size': train_size,\n",
    "                        'embed_dim': embed_dim,\n",
    "                        'hidden_dim': embed_dim * 2,\n",
    "                        'alpha': alpha,\n",
    "                        'learning_rate': lr,\n",
    "                        'input_class': cls,\n",
    "                        'accuracy': acc,\n",
    "                        'batch_pos': batch_pos,\n",
    "                        'batch_neg': len(X_batch) - batch_pos}\n",
    "                    d.update(accs)\n",
    "                    data.append(d)\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\n",
    "    os.path.join(\"results\", \"input-as-output-byclass-results.csv\"),\n",
    "    index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
